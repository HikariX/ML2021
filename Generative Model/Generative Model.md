# Generative Model

在传统的神经网络任务中，输入不同的x，给出不同的y。然而该网络无法处理对于确定输入产生多个输出的问题。例如，对于预测游戏画面，角色在某分叉点可能执行不同的下一步操作，但对应的前序训练资料可能相同，从而网络会产生误解。此时对不同的分叉结果赋予不同的采样概率，即可解决这一问题。如下图所示，当输入x时，同时输入一个分布的采样。对于不同的x选取同一个分布的不同采样，从而输出的y也开始遵循某一个分布。

<img src="image-20210421103225290.png" alt="image-20210421103225290" style="zoom:25%;" />

需要注意的是，用于采样的z分布必须足够简单（能够了解其分布），以便于采样。

***为什么需要分布信息？***

如上所述，当单输入可能对应多输出时，网络将需要数据的更多信息以处理。拟人化讲，这是一种“创造性”的要求。所以对于画面生成、聊天机器人等任务会更多地要求这一特性。

<img src="image-20210421103846487.png" alt="image-20210421103846487" style="zoom:25%;" />

### GAN: Basic

首先以动漫人脸生成任务为例。输入不同的人脸数据x，同时辅以不同的分布向量，网络将会学习并输出对应的复杂分布输出y。

<img src="image-20210421110705247.png" alt="image-20210421110705247" style="zoom:25%;" />

在这一过程中，产生了**Discriminator**的概念。Discriminator，即对某输入进行判定，并输出一标量值。通常定义其输入0-1间的实数，数值越大表明结果越接近。这里的接近是以我们的任务目标来判定的。例如对于动漫人脸生成，如果机器生成的图和目标的动漫人物图风格相似，那么分数将会较高。

<img src="image-20210421110835898.png" alt="image-20210421110835898" style="zoom:25%;" />

#### 基本思路

***仿生学角度：演化***

通过generator进行生成，再通过discriminator进行判别筛选，实际上是一种仿生学过程。首先discriminator判定生成的东西好坏，接下来generator通过这一判定来改进自己的生成结果，再用discriminator进行判别，如此循环。这也是GAN中对抗**adversarial**的由来。但在机器学习任务里是一种合作关系。

<img src="image-20210421111142097.png" alt="image-20210421111142097" style="zoom:25%;" />

#### 训练流程

<img src="image-20210421112205688.png" alt="image-20210421112205688" style="zoom:25%;" />

GAN的训练流程为：首先固定generator，训练discriminator对generator生成的内容和目标内容进行判定。此时discriminator对从数据库中选取的目标内容给予高分，而对生成内容给出低分；接下来固定该discriminator，将generator更新，其发现discriminator的偏好，修改自己的参数，以使得生成结果能够获得高分。如此往复多次，最终完成训练。

在新世代，GAN的效果可以以假乱真，不仅是针对动漫图片，对真实人脸也可达到类似效果。另外，对于某两角度不同的人脸，甚至可以输出其中间的变化：从左脸转动到右脸间的所有图片。

<img src="image-20210421115422649.png" alt="image-20210421115422649" style="zoom:25%;" />