{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML2021Spring - HW1","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb","timestamp":1615803988171}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mz0_QVkxCrX3"},"source":["# **Homework 1: COVID-19 Cases Prediction (Regression)**"]},{"cell_type":"markdown","metadata":{"id":"ZeZnPAiwDRWG"},"source":["Author: Heng-Jui Chang\n","\n","Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n","Video: TBA\n","\n","Objectives:\n","* Solve a regression problem with deep neural networks (DNN).\n","* Understand basic DNN training tips.\n","* Get familiar with PyTorch.\n","\n","If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"]},{"cell_type":"markdown","metadata":{"id":"Jx3x1nDkG-Uy"},"source":["# **Download Data**\n","\n","\n","If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMj55YDKG6ch","executionInfo":{"status":"ok","timestamp":1615857727153,"user_tz":-480,"elapsed":2729,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"c2a27442-de40-46d6-f962-73396b3dfc6f"},"source":["tr_path = 'covid.train.csv'  # path to training data\n","tt_path = 'covid.test.csv'   # path to testing data\n","\n","!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n","!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n","To: /content/covid.train.csv\n","100% 2.00M/2.00M [00:00<00:00, 31.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n","To: /content/covid.test.csv\n","100% 651k/651k [00:00<00:00, 10.3MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wS_4-77xHk44"},"source":["# **Import Some Packages**"]},{"cell_type":"code","metadata":{"id":"k-onQd4JNA5H","executionInfo":{"status":"ok","timestamp":1615857730695,"user_tz":-480,"elapsed":5331,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","# For data preprocess\n","import numpy as np\n","import csv\n","import os\n","\n","# For plotting\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","\n","myseed = 42069  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BtE3b6JEH7rw"},"source":["# **Some Utilities**\n","\n","You do not need to modify this part."]},{"cell_type":"code","metadata":{"id":"FWMT3uf1NGQp","executionInfo":{"status":"ok","timestamp":1615857730695,"user_tz":-480,"elapsed":3772,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def get_device():\n","    ''' Get device (if GPU is available, use GPU) '''\n","    return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# def plot_learning_curve(loss_record, title=''):\n","#     ''' Plot learning curve of your DNN (train & dev loss) '''\n","#     total_steps = len(loss_record['train'])\n","#     x_1 = range(total_steps)\n","#     x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n","#     figure(figsize=(6, 4))\n","#     plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n","#     plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n","#     plt.ylim(0.0, 5.)\n","#     plt.xlabel('Training steps')\n","#     plt.ylabel('MSE loss')\n","#     plt.title('Learning curve of {}'.format(title))\n","#     plt.legend()\n","#     plt.show()\n","\n","def plot_learning_curve_avg(total_loss_record, title=''):\n","    ''' Plot learning curve of your DNN (train & dev loss) '''\n","    total_steps = len(total_loss_record[0]['train'])\n","    x_1 = range(total_steps)\n","    x_2 = x_1[::len(total_loss_record[0]['train']) // len(total_loss_record[0]['dev'])]\n","    figure(figsize=(6, 4))\n","    loss_record_train = 0\n","    loss_record_dev = 0\n","    for i in range(10):\n","        loss_record_train += np.array(total_loss_record[i]['train'])\n","        loss_record_dev += np.array(total_loss_record[i]['dev'])\n","    loss_record_train /= 10\n","    loss_record_dev /= 10\n","    plt.plot(x_1, list(loss_record_train), c='tab:red', label='train')\n","    plt.plot(x_2, list(loss_record_dev), c='tab:cyan', label='dev')\n","    plt.ylim(0.0, 5.)\n","    plt.xlabel('Training steps')\n","    plt.ylabel('MSE loss')\n","    plt.title('Learning curve of {}'.format(title))\n","    plt.legend()\n","    plt.show()\n","\n","def plot_learning_curve_final(loss_record, title=''):\n","    ''' Plot learning curve of your DNN (train & dev loss) '''\n","    total_steps = len(loss_record['final'])\n","    x_1 = range(total_steps)\n","    figure(figsize=(6, 4))\n","    plt.plot(x_1, loss_record['final'], c='tab:red', label='train')\n","    plt.ylim(0.0, 5.)\n","    plt.xlabel('Training steps')\n","    plt.ylabel('MSE loss')\n","    plt.title('Learning curve of {}'.format(title))\n","    plt.legend()\n","    plt.show()\n","\n","\n","def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n","    ''' Plot prediction of your DNN '''\n","    if preds is None or targets is None:\n","        model.eval()\n","        preds, targets = [], []\n","        for x, y in dv_set:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                preds.append(pred.detach().cpu())\n","                targets.append(y.detach().cpu())\n","        preds = torch.cat(preds, dim=0).numpy()\n","        targets = torch.cat(targets, dim=0).numpy()\n","\n","    figure(figsize=(5, 5))\n","    plt.scatter(targets, preds, c='r', alpha=0.5)\n","    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n","    plt.xlim(-0.2, lim)\n","    plt.ylim(-0.2, lim)\n","    plt.xlabel('ground truth value')\n","    plt.ylabel('predicted value')\n","    plt.title('Ground Truth v.s. Prediction')\n","    plt.show()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"39U_XFX6KOoj"},"source":["# **Preprocess**\n","\n","We have three kinds of datasets:\n","* `train`: for training\n","* `dev`: for validation\n","* `test`: for testing (w/o target value)"]},{"cell_type":"markdown","metadata":{"id":"TQ-MdwpLL7Dt"},"source":["## **Dataset**\n","\n","The `COVID19Dataset` below does:\n","* read `.csv` files\n","* extract features\n","* split `covid.train.csv` into train/dev sets\n","* normalize features\n","\n","Finishing `TODO` below might make you pass medium baseline."]},{"cell_type":"code","metadata":{"id":"0zlpIp9ANJRU","executionInfo":{"status":"ok","timestamp":1615863217442,"user_tz":-480,"elapsed":1127,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["class COVID19Dataset(Dataset):\n","    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n","    def __init__(self,\n","                 path,\n","                 fold,\n","                 mean, std,\n","                 mode='train',\n","                 target_only=False):\n","        self.mode = mode\n","\n","        # Read data into numpy arrays\n","        with open(path, 'r') as fp:\n","            data = list(csv.reader(fp))\n","            data = np.array(data[1:])[:, 1:].astype(float)\n","        feats = None\n","        if not target_only:\n","            feats = list(range(93))\n","        else:\n","            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n","            # feats = list(range(40))\n","            # feats.extend([i for i in range(44, 52)])\n","            # feats += [57]\n","            # feats.extend([i for i in range(62, 70)])\n","            # feats += [75]\n","            # feats.extend([i for i in range(80, 88)])\n","\n","            # feats.extend([57, 75])\n","\n","            feats = list(range(40))\n","            feats.extend([i for i in range(40, 52)])\n","            feats += [57]\n","            feats.extend([i for i in range(58, 70)])\n","            feats += [75]\n","            feats.extend([i for i in range(76, 88)])\n","\n","        if mode == 'test':\n","            # Testing data\n","            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n","            data = data[:, feats]\n","            self.data = torch.FloatTensor(data)\n","        else:\n","            # Training data (train/dev sets)\n","            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n","            target = data[:, -1]\n","            data = data[:, feats]\n","            \n","            indices = None\n","            # Splitting training data into train & dev sets\n","            if mode == 'train':\n","                indices = [i for i in range(len(data)) if i % 10 != fold]\n","            elif mode == 'dev':\n","                indices = [i for i in range(len(data)) if i % 10 == fold]\n","            elif mode == 'final': # For test set, get all data to normalize it.\n","                indices = [i for i in range(len(data))]\n","            # Convert data into PyTorch tensors\n","            self.data = torch.FloatTensor(data[indices])\n","            self.target = torch.FloatTensor(target[indices])\n","        \n","        # Normalize features (you may remove this part to see what will happen)\n","        # self.data[:, 40:] = \\\n","        #     (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n","        #     / self.data[:, 40:].std(dim=0, keepdim=True)\n","        if mode == 'train' or mode == 'final':\n","            self.mean =  self.data[:, 40:].mean(dim=0, keepdim=True)\n","            self.std = self.data[:, 40:].std(dim=0, keepdim=True)\n","        else:\n","            self.mean = mean\n","            self.std = std\n","        # print(mode, self.mean, self.std)\n","        self.data[:, 40:] = \\\n","            (self.data[:, 40:] - self.mean) \\\n","            / self.std\n","        self.dim = self.data.shape[1]\n","\n","        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n","              .format(mode, len(self.data), self.dim))\n","    \n","    def getNormalizer(self):\n","        return self.mean, self.std\n","\n","    def __getitem__(self, index):\n","        # Returns one sample at a time\n","        if self.mode in ['train', 'dev', 'final']:\n","            # For training\n","            return self.data[index], self.target[index]\n","        else:\n","            # For testing (no target)\n","            return self.data[index]\n","\n","    def __len__(self):\n","        # Returns the size of the dataset\n","        return len(self.data)"],"execution_count":128,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlhTlkE7MDo3"},"source":["## **DataLoader**\n","\n","A `DataLoader` loads data from a given `Dataset` into batches.\n"]},{"cell_type":"code","metadata":{"id":"hlhLk5t6MBX3","executionInfo":{"status":"ok","timestamp":1615859007510,"user_tz":-480,"elapsed":712,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def prep_dataloader(path, fold, mean, std, mode, batch_size, n_jobs=0, target_only=False):\n","    ''' Generates a dataset, then is put into a dataloader. '''\n","    dataset = COVID19Dataset(path, fold, mean, std, mode, target_only=target_only)  # Construct dataset\n","    mean, std = dataset.getNormalizer()\n","    dataloader = DataLoader(\n","        dataset, batch_size,\n","        shuffle=(mode == 'train' or mode == 'final'), drop_last=False,\n","        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n","    return dataloader, mean, std"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGuycwR0MeQB"},"source":["# **Deep Neural Network**\n","\n","`NeuralNet` is an `nn.Module` designed for regression.\n","The DNN consists of 2 fully-connected layers with ReLU activation.\n","This module also included a function `cal_loss` for calculating loss.\n"]},{"cell_type":"code","metadata":{"id":"49-uXYovOAI0","executionInfo":{"status":"ok","timestamp":1615862856072,"user_tz":-480,"elapsed":584,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["class NeuralNet(nn.Module):\n","    ''' A simple fully-connected deep neural network '''\n","    def __init__(self, input_dim):\n","        super(NeuralNet, self).__init__()\n","\n","        # Define your neural network here\n","        # TODO: How to modify this model to achieve better performance?\n","        # self.net = nn.Sequential(\n","        #     nn.Linear(input_dim, 64),\n","        #     nn.ReLU(),\n","        #     nn.Linear(64, 1)\n","        # )\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, 32),\n","            nn.ReLU(),\n","\n","            nn.Linear(32, 128),\n","            nn.ReLU(),\n","\n","            nn.Linear(128, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 1)\n","        )\n","\n","        # Mean squared error loss\n","        self.criterion = nn.MSELoss(reduction='mean')\n","\n","    def forward(self, x):\n","        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n","        return self.net(x).squeeze(1)\n","\n","    def cal_loss(self, pred, target):\n","        ''' Calculate loss '''\n","        # TODO: you may implement L2 regularization here\n","        return self.criterion(pred, target)"],"execution_count":124,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvFWVjZ5Nvga"},"source":["# **Train/Dev/Test**"]},{"cell_type":"markdown","metadata":{"id":"MAM8QecJOyqn"},"source":["## **Training**"]},{"cell_type":"code","metadata":{"id":"lOqcmYzMO7jB","executionInfo":{"status":"ok","timestamp":1615859010377,"user_tz":-480,"elapsed":414,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def train(config, device):\n","    ''' DNN training '''\n","\n","    n_epochs = config['n_epochs']  # Maximum number of epochs\n","    model = None\n","    total_min_mse = 0\n","    total_loss_record = {}\n","    for fold in range(10):\n","        # Setup fold\n","        tr_set, mean, std = prep_dataloader(tr_path, fold, None, None, 'train', config['batch_size'], n_jobs=0, target_only=target_only)\n","        dv_set, _, _ = prep_dataloader(tr_path, fold, mean, std, 'dev', config['batch_size'], n_jobs=0, target_only=target_only)\n","        # Setup model\n","        model = NeuralNet(tr_set.dataset.dim).to(device)\n","        # Setup optimizer\n","        optimizer = getattr(torch.optim, config['optimizer'])(\n","            model.parameters(), **config['optim_hparas'])\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) # 设置学习率下降\n","        min_mse = 1000.\n","        loss_record = {'train': [], 'dev': []}      # for recording training loss\n","        early_stop_cnt = 0\n","        epoch = 0\n","\n","        while epoch < n_epochs:\n","            model.train()                           # set model to training mode\n","            for x, y in tr_set:                     # iterate through the dataloader\n","                optimizer.zero_grad()               # set gradient to zero\n","                x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n","                pred = model(x)                     # forward pass (compute output)\n","                mse_loss = model.cal_loss(pred, y)  # compute loss\n","                mse_loss.backward()                 # compute gradient (backpropagation)\n","                optimizer.step()                    # update model with optimizer\n","                loss_record['train'].append(mse_loss.detach().cpu().item())\n","            # scheduler.step()\n","            # After each epoch, test your model on the validation (development) set.\n","            dev_mse = dev(dv_set, model, device)\n","            if dev_mse < min_mse:\n","                min_mse = dev_mse\n","                print('Saving model (epoch = {:4d}, loss = {:.4f})'\n","                .format(epoch + 1, min_mse))\n","\n","            epoch += 1\n","            loss_record['dev'].append(dev_mse)\n","            # if early_stop_cnt > config['early_stop']:\n","            #     # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n","            #     break\n","        total_min_mse += min_mse\n","        print('Finished training after {} epochs in fold {}'.format(epoch, fold + 1))\n","        del model\n","        total_loss_record[fold] = loss_record\n","    print('Finished training with avg min mse {}'.format(total_min_mse / 10))\n","    return min_mse, total_loss_record"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-OMOfE420G_","executionInfo":{"status":"ok","timestamp":1615860320990,"user_tz":-480,"elapsed":643,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def train_total(config, device):\n","    ''' DNN training '''\n","\n","    n_epochs = config['n_epochs']  # Maximum number of epochs\n","    model = None\n","    total_min_mse = 0\n","    tr_set, mean, std = prep_dataloader(tr_path, 0, None, None, 'final', config['batch_size'], n_jobs=0, target_only=target_only)\n","    # Setup model\n","    del model\n","    model = NeuralNet(tr_set.dataset.dim).to(device)\n","    # Setup optimizer\n","    optimizer = getattr(torch.optim, config['optimizer'])(\n","        model.parameters(), **config['optim_hparas'])\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) # 设置学习率下降\n","    min_mse = 1000.\n","    loss_record = {'final': []}      # for recording training loss\n","    early_stop_cnt = 0\n","    epoch = 0\n","\n","    while epoch < n_epochs:\n","        model.train()                           # set model to training mode\n","        total_mse = 0\n","        for x, y in tr_set:                     # iterate through the dataloader\n","            optimizer.zero_grad()               # set gradient to zero\n","            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n","            pred = model(x)                     # forward pass (compute output)\n","            mse_loss = model.cal_loss(pred, y)  # compute loss\n","            total_mse += mse_loss.detach().cpu().item() * len(x)\n","            mse_loss.backward()                 # compute gradient (backpropagation)\n","            optimizer.step()                    # update model with optimizer\n","        scheduler.step()\n","        total_mse /= len(tr_set.dataset)\n","        if total_mse < min_mse:\n","            # Save model if your model improved\n","            min_mse = total_mse\n","            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n","                .format(epoch + 1, min_mse))\n","            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n","            early_stop_cnt = 0\n","        else:\n","            early_stop_cnt += 1\n","\n","        epoch += 1\n","        loss_record['final'].append(total_mse)\n","        if early_stop_cnt > config['early_stop']:\n","            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n","            break\n","    print('Finished training')\n","    return min_mse, loss_record"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hSd4Bn3O2PL"},"source":["## **Validation**"]},{"cell_type":"code","metadata":{"id":"yrxrD3YsN3U2","executionInfo":{"status":"ok","timestamp":1615860322445,"user_tz":-480,"elapsed":731,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def dev(dv_set, model, device):\n","    model.eval()                                # set model to evalutation mode\n","    total_loss = 0\n","    for x, y in dv_set:                         # iterate through the dataloader\n","        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n","        with torch.no_grad():                   # disable gradient calculation\n","            pred = model(x)                     # forward pass (compute output)\n","            mse_loss = model.cal_loss(pred, y)  # compute loss\n","        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n","    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n","    return total_loss"],"execution_count":106,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0pdrhQAO41L"},"source":["## **Testing**"]},{"cell_type":"code","metadata":{"id":"aSBMRFlYN5tB","executionInfo":{"status":"ok","timestamp":1615858891835,"user_tz":-480,"elapsed":423,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["def test(tt_set, model, device):\n","    model.eval()                                # set model to evalutation mode\n","    preds = []\n","    for x in tt_set:                            # iterate through the dataloader\n","        x = x.to(device)                        # move data to device (cpu/cuda)\n","        with torch.no_grad():                   # disable gradient calculation\n","            pred = model(x)                     # forward pass (compute output)\n","            preds.append(pred.detach().cpu())   # collect prediction\n","    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n","    return preds"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvckkF5dvf0j"},"source":["# **Setup Hyper-parameters**\n","\n","`config` contains hyper-parameters for training and the path to save your model."]},{"cell_type":"code","metadata":{"id":"NPXpdumwPjE7","executionInfo":{"status":"ok","timestamp":1615861357740,"user_tz":-480,"elapsed":563,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}}},"source":["device = get_device()                 # get the current available device ('cpu' or 'cuda')\n","os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n","target_only = True                   # TODO: Using 40 states & 2 tested_positive features\n","\n","# TODO: How to tune these hyper-parameters to improve your model's performance?\n","config = {\n","    'n_epochs': 1000,                # maximum number of epochs\n","    'batch_size': 270,               # mini-batch size for dataloader\n","    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n","    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n","        'lr': 0.001,                 # learning rate of SGD\n","        'momentum': 0.8              # momentum for SGD\n","    },\n","    'weight_decay': 0.0001,\n","    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n","    'save_path': 'models/model.pth'  # your model will be saved here\n","}"],"execution_count":118,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6j1eOV3TOH-j"},"source":["# **Load data and model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNrYBMmePLKm","executionInfo":{"status":"ok","timestamp":1615863471740,"user_tz":-480,"elapsed":808,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"958f498a-bc57-4fd6-8b59-d6280484fc49"},"source":["_, mean, std = prep_dataloader(tr_path, 0, None, None, 'final', config['batch_size'], n_jobs=0, target_only=target_only)\n","tt_set, _, _ = prep_dataloader(tt_path, 0, mean, std, 'test', config['batch_size'], n_jobs=0, target_only=target_only)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["Finished reading the final set of COVID19 Dataset (2700 samples found, each dim = 78)\n","Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 78)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sX2B_zgSOPTJ"},"source":["# **Start Training!**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrEbUxazQAAZ","executionInfo":{"status":"ok","timestamp":1615863470923,"user_tz":-480,"elapsed":249332,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"ddf72f57-11d0-4344-e87b-07f814730f08"},"source":["model_loss, model_loss_record = train(config, device)"],"execution_count":129,"outputs":[{"output_type":"stream","text":["Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 278.6034)\n","Saving model (epoch =    2, loss = 29.4201)\n","Saving model (epoch =    3, loss = 13.0250)\n","Saving model (epoch =    4, loss = 8.6079)\n","Saving model (epoch =    5, loss = 4.8102)\n","Saving model (epoch =    6, loss = 3.3736)\n","Saving model (epoch =    7, loss = 2.6699)\n","Saving model (epoch =    8, loss = 2.2453)\n","Saving model (epoch =    9, loss = 2.0044)\n","Saving model (epoch =   10, loss = 1.7936)\n","Saving model (epoch =   11, loss = 1.6211)\n","Saving model (epoch =   12, loss = 1.5177)\n","Saving model (epoch =   13, loss = 1.4136)\n","Saving model (epoch =   14, loss = 1.3592)\n","Saving model (epoch =   15, loss = 1.3267)\n","Saving model (epoch =   16, loss = 1.2639)\n","Saving model (epoch =   17, loss = 1.2107)\n","Saving model (epoch =   18, loss = 1.2051)\n","Saving model (epoch =   19, loss = 1.1610)\n","Saving model (epoch =   20, loss = 1.1491)\n","Saving model (epoch =   22, loss = 1.1339)\n","Saving model (epoch =   23, loss = 1.1339)\n","Saving model (epoch =   25, loss = 1.0897)\n","Saving model (epoch =   26, loss = 1.0636)\n","Saving model (epoch =   27, loss = 1.0624)\n","Saving model (epoch =   29, loss = 1.0409)\n","Saving model (epoch =   30, loss = 1.0231)\n","Saving model (epoch =   33, loss = 1.0047)\n","Saving model (epoch =   37, loss = 0.9730)\n","Saving model (epoch =   43, loss = 0.9435)\n","Saving model (epoch =   46, loss = 0.9434)\n","Saving model (epoch =   49, loss = 0.9338)\n","Saving model (epoch =   52, loss = 0.9264)\n","Saving model (epoch =   57, loss = 0.9070)\n","Saving model (epoch =   61, loss = 0.9037)\n","Saving model (epoch =   62, loss = 0.8979)\n","Saving model (epoch =   64, loss = 0.8931)\n","Saving model (epoch =   67, loss = 0.8798)\n","Saving model (epoch =   68, loss = 0.8721)\n","Saving model (epoch =   74, loss = 0.8662)\n","Saving model (epoch =   77, loss = 0.8572)\n","Saving model (epoch =   87, loss = 0.8475)\n","Saving model (epoch =   96, loss = 0.8382)\n","Saving model (epoch =  103, loss = 0.8290)\n","Saving model (epoch =  126, loss = 0.8278)\n","Saving model (epoch =  128, loss = 0.8211)\n","Saving model (epoch =  154, loss = 0.8163)\n","Finished training after 1000 epochs in fold 1\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 277.0840)\n","Saving model (epoch =    2, loss = 69.9367)\n","Saving model (epoch =    3, loss = 14.7938)\n","Saving model (epoch =    4, loss = 9.3620)\n","Saving model (epoch =    5, loss = 5.5643)\n","Saving model (epoch =    6, loss = 3.9634)\n","Saving model (epoch =    7, loss = 2.8950)\n","Saving model (epoch =    8, loss = 2.3800)\n","Saving model (epoch =    9, loss = 2.1224)\n","Saving model (epoch =   10, loss = 1.9390)\n","Saving model (epoch =   11, loss = 1.7460)\n","Saving model (epoch =   12, loss = 1.6048)\n","Saving model (epoch =   13, loss = 1.5018)\n","Saving model (epoch =   14, loss = 1.4869)\n","Saving model (epoch =   15, loss = 1.4310)\n","Saving model (epoch =   16, loss = 1.3375)\n","Saving model (epoch =   19, loss = 1.3274)\n","Saving model (epoch =   20, loss = 1.2559)\n","Saving model (epoch =   21, loss = 1.2287)\n","Saving model (epoch =   23, loss = 1.2187)\n","Saving model (epoch =   24, loss = 1.2112)\n","Saving model (epoch =   25, loss = 1.1977)\n","Saving model (epoch =   26, loss = 1.1789)\n","Saving model (epoch =   28, loss = 1.1692)\n","Saving model (epoch =   30, loss = 1.1656)\n","Saving model (epoch =   31, loss = 1.1588)\n","Saving model (epoch =   33, loss = 1.1554)\n","Saving model (epoch =   34, loss = 1.1513)\n","Saving model (epoch =   35, loss = 1.1340)\n","Saving model (epoch =   36, loss = 1.1306)\n","Saving model (epoch =   39, loss = 1.1216)\n","Saving model (epoch =   41, loss = 1.1123)\n","Saving model (epoch =   44, loss = 1.0978)\n","Saving model (epoch =   48, loss = 1.0872)\n","Saving model (epoch =   54, loss = 1.0776)\n","Saving model (epoch =   55, loss = 1.0771)\n","Saving model (epoch =   57, loss = 1.0674)\n","Saving model (epoch =   61, loss = 1.0645)\n","Saving model (epoch =   63, loss = 1.0644)\n","Saving model (epoch =   66, loss = 1.0582)\n","Saving model (epoch =   77, loss = 1.0510)\n","Saving model (epoch =   78, loss = 1.0412)\n","Saving model (epoch =   83, loss = 1.0400)\n","Saving model (epoch =   92, loss = 1.0315)\n","Saving model (epoch =   98, loss = 1.0230)\n","Saving model (epoch =  127, loss = 1.0207)\n","Saving model (epoch =  132, loss = 1.0173)\n","Saving model (epoch =  133, loss = 1.0108)\n","Saving model (epoch =  135, loss = 1.0089)\n","Saving model (epoch =  142, loss = 1.0059)\n","Saving model (epoch =  199, loss = 1.0058)\n","Saving model (epoch =  225, loss = 1.0056)\n","Saving model (epoch =  237, loss = 1.0049)\n","Saving model (epoch =  242, loss = 1.0026)\n","Saving model (epoch =  306, loss = 1.0020)\n","Saving model (epoch =  454, loss = 1.0012)\n","Finished training after 1000 epochs in fold 2\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 246.0723)\n","Saving model (epoch =    2, loss = 47.0133)\n","Saving model (epoch =    3, loss = 11.0496)\n","Saving model (epoch =    4, loss = 6.9088)\n","Saving model (epoch =    5, loss = 5.1075)\n","Saving model (epoch =    6, loss = 3.7219)\n","Saving model (epoch =    7, loss = 3.2545)\n","Saving model (epoch =    8, loss = 2.7015)\n","Saving model (epoch =    9, loss = 2.3967)\n","Saving model (epoch =   10, loss = 2.1638)\n","Saving model (epoch =   11, loss = 1.7822)\n","Saving model (epoch =   12, loss = 1.5383)\n","Saving model (epoch =   13, loss = 1.4726)\n","Saving model (epoch =   14, loss = 1.3548)\n","Saving model (epoch =   16, loss = 1.3209)\n","Saving model (epoch =   17, loss = 1.2849)\n","Saving model (epoch =   18, loss = 1.1718)\n","Saving model (epoch =   19, loss = 1.1340)\n","Saving model (epoch =   23, loss = 1.0746)\n","Saving model (epoch =   27, loss = 1.0416)\n","Saving model (epoch =   31, loss = 1.0301)\n","Saving model (epoch =   33, loss = 1.0213)\n","Saving model (epoch =   36, loss = 0.9944)\n","Saving model (epoch =   40, loss = 0.9912)\n","Saving model (epoch =   42, loss = 0.9706)\n","Saving model (epoch =   47, loss = 0.9676)\n","Saving model (epoch =   50, loss = 0.9501)\n","Saving model (epoch =   56, loss = 0.9354)\n","Saving model (epoch =   60, loss = 0.9315)\n","Saving model (epoch =   65, loss = 0.9199)\n","Saving model (epoch =   70, loss = 0.9189)\n","Saving model (epoch =   84, loss = 0.9160)\n","Saving model (epoch =   87, loss = 0.9158)\n","Saving model (epoch =  109, loss = 0.9092)\n","Saving model (epoch =  127, loss = 0.9034)\n","Saving model (epoch =  163, loss = 0.8986)\n","Saving model (epoch =  184, loss = 0.8937)\n","Saving model (epoch =  196, loss = 0.8893)\n","Saving model (epoch =  250, loss = 0.8807)\n","Saving model (epoch =  259, loss = 0.8792)\n","Saving model (epoch =  265, loss = 0.8784)\n","Saving model (epoch =  306, loss = 0.8767)\n","Saving model (epoch =  311, loss = 0.8683)\n","Saving model (epoch =  316, loss = 0.8653)\n","Saving model (epoch =  414, loss = 0.8609)\n","Saving model (epoch =  437, loss = 0.8577)\n","Saving model (epoch =  484, loss = 0.8571)\n","Saving model (epoch =  527, loss = 0.8551)\n","Saving model (epoch =  537, loss = 0.8551)\n","Saving model (epoch =  540, loss = 0.8549)\n","Saving model (epoch =  545, loss = 0.8505)\n","Saving model (epoch =  605, loss = 0.8479)\n","Saving model (epoch =  633, loss = 0.8434)\n","Saving model (epoch =  685, loss = 0.8427)\n","Saving model (epoch =  692, loss = 0.8385)\n","Saving model (epoch =  780, loss = 0.8379)\n","Saving model (epoch =  804, loss = 0.8331)\n","Saving model (epoch =  829, loss = 0.8314)\n","Saving model (epoch =  918, loss = 0.8291)\n","Finished training after 1000 epochs in fold 3\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 270.6606)\n","Saving model (epoch =    2, loss = 27.9263)\n","Saving model (epoch =    3, loss = 16.2103)\n","Saving model (epoch =    4, loss = 8.0518)\n","Saving model (epoch =    5, loss = 5.6808)\n","Saving model (epoch =    6, loss = 4.2246)\n","Saving model (epoch =    7, loss = 3.4239)\n","Saving model (epoch =    8, loss = 2.8029)\n","Saving model (epoch =    9, loss = 2.3368)\n","Saving model (epoch =   10, loss = 1.9811)\n","Saving model (epoch =   11, loss = 1.7442)\n","Saving model (epoch =   12, loss = 1.5851)\n","Saving model (epoch =   13, loss = 1.4590)\n","Saving model (epoch =   15, loss = 1.2903)\n","Saving model (epoch =   16, loss = 1.2122)\n","Saving model (epoch =   17, loss = 1.2059)\n","Saving model (epoch =   18, loss = 1.1416)\n","Saving model (epoch =   19, loss = 1.1238)\n","Saving model (epoch =   20, loss = 1.0836)\n","Saving model (epoch =   21, loss = 1.0551)\n","Saving model (epoch =   24, loss = 1.0303)\n","Saving model (epoch =   25, loss = 1.0021)\n","Saving model (epoch =   29, loss = 0.9942)\n","Saving model (epoch =   31, loss = 0.9463)\n","Saving model (epoch =   34, loss = 0.9311)\n","Saving model (epoch =   35, loss = 0.9229)\n","Saving model (epoch =   38, loss = 0.9218)\n","Saving model (epoch =   39, loss = 0.9016)\n","Saving model (epoch =   42, loss = 0.8927)\n","Saving model (epoch =   43, loss = 0.8920)\n","Saving model (epoch =   44, loss = 0.8903)\n","Saving model (epoch =   47, loss = 0.8788)\n","Saving model (epoch =   48, loss = 0.8681)\n","Saving model (epoch =   50, loss = 0.8647)\n","Saving model (epoch =   54, loss = 0.8467)\n","Saving model (epoch =   56, loss = 0.8444)\n","Saving model (epoch =   58, loss = 0.8325)\n","Saving model (epoch =   64, loss = 0.8322)\n","Saving model (epoch =   68, loss = 0.8320)\n","Saving model (epoch =   69, loss = 0.8283)\n","Saving model (epoch =   71, loss = 0.8132)\n","Saving model (epoch =   73, loss = 0.8065)\n","Saving model (epoch =   78, loss = 0.7986)\n","Saving model (epoch =   83, loss = 0.7959)\n","Saving model (epoch =   92, loss = 0.7890)\n","Saving model (epoch =   97, loss = 0.7778)\n","Saving model (epoch =  100, loss = 0.7769)\n","Saving model (epoch =  104, loss = 0.7767)\n","Saving model (epoch =  115, loss = 0.7694)\n","Saving model (epoch =  127, loss = 0.7609)\n","Saving model (epoch =  128, loss = 0.7601)\n","Saving model (epoch =  139, loss = 0.7553)\n","Saving model (epoch =  227, loss = 0.7531)\n","Saving model (epoch =  230, loss = 0.7508)\n","Finished training after 1000 epochs in fold 4\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 278.3302)\n","Saving model (epoch =    2, loss = 69.9482)\n","Saving model (epoch =    3, loss = 11.8489)\n","Saving model (epoch =    4, loss = 11.1599)\n","Saving model (epoch =    5, loss = 5.7503)\n","Saving model (epoch =    6, loss = 3.6177)\n","Saving model (epoch =    7, loss = 2.6738)\n","Saving model (epoch =    8, loss = 2.2247)\n","Saving model (epoch =    9, loss = 1.8832)\n","Saving model (epoch =   10, loss = 1.7600)\n","Saving model (epoch =   11, loss = 1.6017)\n","Saving model (epoch =   12, loss = 1.5318)\n","Saving model (epoch =   13, loss = 1.4357)\n","Saving model (epoch =   15, loss = 1.3443)\n","Saving model (epoch =   17, loss = 1.2738)\n","Saving model (epoch =   18, loss = 1.2719)\n","Saving model (epoch =   19, loss = 1.2420)\n","Saving model (epoch =   20, loss = 1.2292)\n","Saving model (epoch =   21, loss = 1.2205)\n","Saving model (epoch =   22, loss = 1.2074)\n","Saving model (epoch =   24, loss = 1.1997)\n","Saving model (epoch =   25, loss = 1.1787)\n","Saving model (epoch =   27, loss = 1.1765)\n","Saving model (epoch =   28, loss = 1.1739)\n","Saving model (epoch =   29, loss = 1.1678)\n","Saving model (epoch =   30, loss = 1.1421)\n","Saving model (epoch =   33, loss = 1.1353)\n","Saving model (epoch =   35, loss = 1.1288)\n","Saving model (epoch =   36, loss = 1.1152)\n","Saving model (epoch =   39, loss = 1.1121)\n","Saving model (epoch =   40, loss = 1.1118)\n","Saving model (epoch =   41, loss = 1.1077)\n","Saving model (epoch =   43, loss = 1.1018)\n","Saving model (epoch =   46, loss = 1.1015)\n","Saving model (epoch =   47, loss = 1.0886)\n","Saving model (epoch =   49, loss = 1.0879)\n","Saving model (epoch =   53, loss = 1.0819)\n","Saving model (epoch =   57, loss = 1.0749)\n","Saving model (epoch =   62, loss = 1.0726)\n","Saving model (epoch =   72, loss = 1.0649)\n","Saving model (epoch =   76, loss = 1.0590)\n","Saving model (epoch =  113, loss = 1.0570)\n","Saving model (epoch =  126, loss = 1.0563)\n","Saving model (epoch =  130, loss = 1.0534)\n","Saving model (epoch =  134, loss = 1.0440)\n","Saving model (epoch =  231, loss = 1.0431)\n","Saving model (epoch =  334, loss = 1.0388)\n","Saving model (epoch =  393, loss = 1.0376)\n","Saving model (epoch =  418, loss = 1.0345)\n","Saving model (epoch =  462, loss = 1.0336)\n","Saving model (epoch =  477, loss = 1.0306)\n","Saving model (epoch =  496, loss = 1.0286)\n","Saving model (epoch =  528, loss = 1.0251)\n","Saving model (epoch =  586, loss = 1.0225)\n","Saving model (epoch =  602, loss = 1.0215)\n","Saving model (epoch =  646, loss = 1.0205)\n","Saving model (epoch =  663, loss = 1.0176)\n","Saving model (epoch =  694, loss = 1.0156)\n","Saving model (epoch =  735, loss = 1.0148)\n","Saving model (epoch =  780, loss = 1.0127)\n","Saving model (epoch =  794, loss = 1.0084)\n","Finished training after 1000 epochs in fold 5\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 239.9977)\n","Saving model (epoch =    2, loss = 63.4468)\n","Saving model (epoch =    3, loss = 19.5287)\n","Saving model (epoch =    4, loss = 8.7690)\n","Saving model (epoch =    5, loss = 6.3824)\n","Saving model (epoch =    6, loss = 4.3214)\n","Saving model (epoch =    7, loss = 3.1586)\n","Saving model (epoch =    8, loss = 2.5097)\n","Saving model (epoch =    9, loss = 2.0963)\n","Saving model (epoch =   10, loss = 1.8443)\n","Saving model (epoch =   11, loss = 1.6210)\n","Saving model (epoch =   12, loss = 1.5160)\n","Saving model (epoch =   13, loss = 1.4451)\n","Saving model (epoch =   14, loss = 1.3611)\n","Saving model (epoch =   15, loss = 1.2461)\n","Saving model (epoch =   16, loss = 1.2076)\n","Saving model (epoch =   17, loss = 1.1823)\n","Saving model (epoch =   18, loss = 1.1516)\n","Saving model (epoch =   20, loss = 1.1214)\n","Saving model (epoch =   21, loss = 1.0909)\n","Saving model (epoch =   22, loss = 1.0588)\n","Saving model (epoch =   26, loss = 1.0148)\n","Saving model (epoch =   29, loss = 0.9757)\n","Saving model (epoch =   31, loss = 0.9656)\n","Saving model (epoch =   39, loss = 0.9155)\n","Saving model (epoch =   40, loss = 0.9075)\n","Saving model (epoch =   46, loss = 0.9018)\n","Saving model (epoch =   49, loss = 0.8795)\n","Saving model (epoch =   54, loss = 0.8607)\n","Saving model (epoch =   57, loss = 0.8433)\n","Saving model (epoch =   60, loss = 0.8357)\n","Saving model (epoch =   61, loss = 0.8294)\n","Saving model (epoch =   70, loss = 0.8279)\n","Saving model (epoch =   73, loss = 0.8182)\n","Saving model (epoch =   76, loss = 0.8018)\n","Saving model (epoch =   82, loss = 0.7978)\n","Saving model (epoch =   85, loss = 0.7964)\n","Saving model (epoch =   88, loss = 0.7943)\n","Saving model (epoch =   89, loss = 0.7931)\n","Saving model (epoch =   96, loss = 0.7795)\n","Saving model (epoch =  105, loss = 0.7763)\n","Saving model (epoch =  107, loss = 0.7757)\n","Saving model (epoch =  121, loss = 0.7595)\n","Saving model (epoch =  132, loss = 0.7572)\n","Saving model (epoch =  134, loss = 0.7532)\n","Saving model (epoch =  139, loss = 0.7492)\n","Saving model (epoch =  164, loss = 0.7413)\n","Saving model (epoch =  196, loss = 0.7381)\n","Saving model (epoch =  203, loss = 0.7374)\n","Saving model (epoch =  229, loss = 0.7335)\n","Saving model (epoch =  246, loss = 0.7326)\n","Saving model (epoch =  292, loss = 0.7195)\n","Saving model (epoch =  382, loss = 0.7179)\n","Saving model (epoch =  669, loss = 0.7177)\n","Saving model (epoch =  849, loss = 0.7175)\n","Finished training after 1000 epochs in fold 6\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 290.1681)\n","Saving model (epoch =    2, loss = 39.4920)\n","Saving model (epoch =    3, loss = 21.3247)\n","Saving model (epoch =    4, loss = 10.1194)\n","Saving model (epoch =    5, loss = 6.1983)\n","Saving model (epoch =    6, loss = 4.3523)\n","Saving model (epoch =    7, loss = 3.2500)\n","Saving model (epoch =    8, loss = 2.5106)\n","Saving model (epoch =    9, loss = 2.1921)\n","Saving model (epoch =   10, loss = 1.9652)\n","Saving model (epoch =   11, loss = 1.8215)\n","Saving model (epoch =   12, loss = 1.6705)\n","Saving model (epoch =   13, loss = 1.5680)\n","Saving model (epoch =   14, loss = 1.4958)\n","Saving model (epoch =   15, loss = 1.4171)\n","Saving model (epoch =   16, loss = 1.4001)\n","Saving model (epoch =   17, loss = 1.3378)\n","Saving model (epoch =   18, loss = 1.3118)\n","Saving model (epoch =   19, loss = 1.2895)\n","Saving model (epoch =   22, loss = 1.2432)\n","Saving model (epoch =   23, loss = 1.2068)\n","Saving model (epoch =   25, loss = 1.1994)\n","Saving model (epoch =   26, loss = 1.1697)\n","Saving model (epoch =   29, loss = 1.1555)\n","Saving model (epoch =   31, loss = 1.1243)\n","Saving model (epoch =   33, loss = 1.1026)\n","Saving model (epoch =   34, loss = 1.0987)\n","Saving model (epoch =   38, loss = 1.0801)\n","Saving model (epoch =   41, loss = 1.0628)\n","Saving model (epoch =   43, loss = 1.0489)\n","Saving model (epoch =   47, loss = 1.0335)\n","Saving model (epoch =   52, loss = 1.0239)\n","Saving model (epoch =   56, loss = 1.0140)\n","Saving model (epoch =   57, loss = 1.0082)\n","Saving model (epoch =   58, loss = 1.0021)\n","Saving model (epoch =   61, loss = 0.9980)\n","Saving model (epoch =   62, loss = 0.9859)\n","Saving model (epoch =   67, loss = 0.9812)\n","Saving model (epoch =   70, loss = 0.9807)\n","Saving model (epoch =   73, loss = 0.9720)\n","Saving model (epoch =   79, loss = 0.9696)\n","Saving model (epoch =   82, loss = 0.9570)\n","Saving model (epoch =   95, loss = 0.9540)\n","Saving model (epoch =  109, loss = 0.9474)\n","Saving model (epoch =  110, loss = 0.9430)\n","Saving model (epoch =  111, loss = 0.9364)\n","Saving model (epoch =  123, loss = 0.9337)\n","Saving model (epoch =  173, loss = 0.9307)\n","Saving model (epoch =  186, loss = 0.9304)\n","Saving model (epoch =  259, loss = 0.9299)\n","Saving model (epoch =  273, loss = 0.9298)\n","Saving model (epoch =  660, loss = 0.9289)\n","Saving model (epoch =  832, loss = 0.9288)\n","Saving model (epoch =  862, loss = 0.9281)\n","Saving model (epoch =  866, loss = 0.9248)\n","Saving model (epoch =  956, loss = 0.9239)\n","Finished training after 1000 epochs in fold 7\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 284.6244)\n","Saving model (epoch =    2, loss = 82.4656)\n","Saving model (epoch =    3, loss = 12.8449)\n","Saving model (epoch =    4, loss = 8.9893)\n","Saving model (epoch =    5, loss = 6.1854)\n","Saving model (epoch =    6, loss = 4.5141)\n","Saving model (epoch =    7, loss = 3.4709)\n","Saving model (epoch =    8, loss = 2.8362)\n","Saving model (epoch =    9, loss = 2.5231)\n","Saving model (epoch =   10, loss = 2.2475)\n","Saving model (epoch =   11, loss = 2.0756)\n","Saving model (epoch =   12, loss = 1.9709)\n","Saving model (epoch =   13, loss = 1.8396)\n","Saving model (epoch =   14, loss = 1.6671)\n","Saving model (epoch =   15, loss = 1.5516)\n","Saving model (epoch =   16, loss = 1.4849)\n","Saving model (epoch =   17, loss = 1.4359)\n","Saving model (epoch =   19, loss = 1.3945)\n","Saving model (epoch =   20, loss = 1.3384)\n","Saving model (epoch =   22, loss = 1.3202)\n","Saving model (epoch =   23, loss = 1.2744)\n","Saving model (epoch =   24, loss = 1.2475)\n","Saving model (epoch =   26, loss = 1.2469)\n","Saving model (epoch =   27, loss = 1.2428)\n","Saving model (epoch =   28, loss = 1.2288)\n","Saving model (epoch =   31, loss = 1.1854)\n","Saving model (epoch =   35, loss = 1.1821)\n","Saving model (epoch =   36, loss = 1.1624)\n","Saving model (epoch =   39, loss = 1.1599)\n","Saving model (epoch =   40, loss = 1.1505)\n","Saving model (epoch =   47, loss = 1.1484)\n","Saving model (epoch =   48, loss = 1.1419)\n","Saving model (epoch =   49, loss = 1.1378)\n","Saving model (epoch =   53, loss = 1.1277)\n","Saving model (epoch =   54, loss = 1.1236)\n","Saving model (epoch =   58, loss = 1.1123)\n","Saving model (epoch =   60, loss = 1.1060)\n","Saving model (epoch =   61, loss = 1.0984)\n","Saving model (epoch =   70, loss = 1.0978)\n","Saving model (epoch =   72, loss = 1.0920)\n","Saving model (epoch =   75, loss = 1.0881)\n","Saving model (epoch =   77, loss = 1.0799)\n","Saving model (epoch =   81, loss = 1.0748)\n","Saving model (epoch =   92, loss = 1.0715)\n","Saving model (epoch =   96, loss = 1.0669)\n","Saving model (epoch =  108, loss = 1.0637)\n","Saving model (epoch =  117, loss = 1.0525)\n","Saving model (epoch =  139, loss = 1.0519)\n","Saving model (epoch =  161, loss = 1.0473)\n","Saving model (epoch =  235, loss = 1.0382)\n","Saving model (epoch =  276, loss = 1.0352)\n","Saving model (epoch =  401, loss = 1.0351)\n","Saving model (epoch =  451, loss = 1.0345)\n","Saving model (epoch =  656, loss = 1.0314)\n","Saving model (epoch =  659, loss = 1.0285)\n","Saving model (epoch =  719, loss = 1.0238)\n","Saving model (epoch =  735, loss = 1.0235)\n","Saving model (epoch =  778, loss = 1.0216)\n","Finished training after 1000 epochs in fold 8\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 264.0032)\n","Saving model (epoch =    2, loss = 43.3184)\n","Saving model (epoch =    3, loss = 13.1910)\n","Saving model (epoch =    4, loss = 6.1681)\n","Saving model (epoch =    5, loss = 4.1677)\n","Saving model (epoch =    6, loss = 3.0905)\n","Saving model (epoch =    7, loss = 2.5272)\n","Saving model (epoch =    8, loss = 2.1970)\n","Saving model (epoch =    9, loss = 1.9099)\n","Saving model (epoch =   10, loss = 1.6813)\n","Saving model (epoch =   11, loss = 1.5389)\n","Saving model (epoch =   12, loss = 1.3963)\n","Saving model (epoch =   13, loss = 1.3273)\n","Saving model (epoch =   14, loss = 1.3104)\n","Saving model (epoch =   15, loss = 1.2132)\n","Saving model (epoch =   16, loss = 1.1963)\n","Saving model (epoch =   17, loss = 1.1511)\n","Saving model (epoch =   18, loss = 1.1126)\n","Saving model (epoch =   19, loss = 1.1001)\n","Saving model (epoch =   20, loss = 1.0686)\n","Saving model (epoch =   21, loss = 1.0479)\n","Saving model (epoch =   22, loss = 1.0381)\n","Saving model (epoch =   23, loss = 1.0183)\n","Saving model (epoch =   26, loss = 0.9867)\n","Saving model (epoch =   29, loss = 0.9593)\n","Saving model (epoch =   30, loss = 0.9492)\n","Saving model (epoch =   31, loss = 0.9464)\n","Saving model (epoch =   34, loss = 0.9299)\n","Saving model (epoch =   36, loss = 0.9226)\n","Saving model (epoch =   38, loss = 0.9140)\n","Saving model (epoch =   39, loss = 0.9118)\n","Saving model (epoch =   41, loss = 0.9029)\n","Saving model (epoch =   44, loss = 0.8838)\n","Saving model (epoch =   50, loss = 0.8798)\n","Saving model (epoch =   54, loss = 0.8658)\n","Saving model (epoch =   56, loss = 0.8569)\n","Saving model (epoch =   57, loss = 0.8527)\n","Saving model (epoch =   64, loss = 0.8489)\n","Saving model (epoch =   68, loss = 0.8377)\n","Saving model (epoch =   71, loss = 0.8356)\n","Saving model (epoch =   79, loss = 0.8292)\n","Saving model (epoch =   85, loss = 0.8237)\n","Saving model (epoch =  102, loss = 0.8189)\n","Saving model (epoch =  110, loss = 0.8155)\n","Finished training after 1000 epochs in fold 9\n","Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 78)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 291.4530)\n","Saving model (epoch =    2, loss = 79.3783)\n","Saving model (epoch =    3, loss = 15.2886)\n","Saving model (epoch =    4, loss = 9.9339)\n","Saving model (epoch =    5, loss = 5.8021)\n","Saving model (epoch =    6, loss = 3.9629)\n","Saving model (epoch =    7, loss = 2.9313)\n","Saving model (epoch =    8, loss = 2.3656)\n","Saving model (epoch =    9, loss = 2.0204)\n","Saving model (epoch =   10, loss = 1.8230)\n","Saving model (epoch =   11, loss = 1.6611)\n","Saving model (epoch =   12, loss = 1.4746)\n","Saving model (epoch =   13, loss = 1.3794)\n","Saving model (epoch =   14, loss = 1.3146)\n","Saving model (epoch =   15, loss = 1.2994)\n","Saving model (epoch =   16, loss = 1.2358)\n","Saving model (epoch =   17, loss = 1.2141)\n","Saving model (epoch =   20, loss = 1.1658)\n","Saving model (epoch =   21, loss = 1.1365)\n","Saving model (epoch =   23, loss = 1.1144)\n","Saving model (epoch =   24, loss = 1.1117)\n","Saving model (epoch =   28, loss = 1.0975)\n","Saving model (epoch =   30, loss = 1.0836)\n","Saving model (epoch =   36, loss = 1.0561)\n","Saving model (epoch =   39, loss = 1.0555)\n","Saving model (epoch =   44, loss = 1.0324)\n","Saving model (epoch =   46, loss = 1.0235)\n","Saving model (epoch =   48, loss = 1.0203)\n","Saving model (epoch =   52, loss = 1.0202)\n","Saving model (epoch =   54, loss = 1.0096)\n","Saving model (epoch =   58, loss = 1.0056)\n","Saving model (epoch =   62, loss = 0.9892)\n","Saving model (epoch =   69, loss = 0.9856)\n","Saving model (epoch =   70, loss = 0.9708)\n","Saving model (epoch =   73, loss = 0.9618)\n","Saving model (epoch =   88, loss = 0.9587)\n","Saving model (epoch =   91, loss = 0.9534)\n","Saving model (epoch =   92, loss = 0.9406)\n","Saving model (epoch =  100, loss = 0.9290)\n","Saving model (epoch =  123, loss = 0.9209)\n","Saving model (epoch =  125, loss = 0.9174)\n","Saving model (epoch =  132, loss = 0.9153)\n","Saving model (epoch =  141, loss = 0.9119)\n","Saving model (epoch =  167, loss = 0.9115)\n","Saving model (epoch =  185, loss = 0.9077)\n","Saving model (epoch =  193, loss = 0.9074)\n","Saving model (epoch =  211, loss = 0.9020)\n","Saving model (epoch =  251, loss = 0.9014)\n","Saving model (epoch =  330, loss = 0.8955)\n","Saving model (epoch =  660, loss = 0.8951)\n","Saving model (epoch =  793, loss = 0.8943)\n","Finished training after 1000 epochs in fold 10\n","Finished training with avg min mse 0.8778759002685547\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"hsNO9nnXQBvP","executionInfo":{"status":"ok","timestamp":1615863185436,"user_tz":-480,"elapsed":1328,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"6fd41a79-24cb-41fe-9645-b046eb0eb32a"},"source":["plot_learning_curve_avg(model_loss_record, title='deep model')"],"execution_count":127,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"3iZTVn5WQFpX","executionInfo":{"status":"error","timestamp":1615794449383,"user_tz":-480,"elapsed":1023,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"ea3ed581-d98f-4734-bc10-8a08402d3d64"},"source":["# del model\n","# model = NeuralNet(tt_set.dataset.dim).to(device)\n","# ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n","# model.load_state_dict(ckpt)\n","# plot_pred(dv_set, model, device)  # Show prediction on the validation set"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-104-e9d7dfe40939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load your best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdv_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Show prediction on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dv_set' is not defined"]}]},{"cell_type":"code","metadata":{"id":"UWwc8lx17Yc3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615861379408,"user_tz":-480,"elapsed":16440,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"24fc56af-7eba-4ccc-c248-ded05abd3166"},"source":["model_loss, model_loss_record = train_total(config, device)"],"execution_count":120,"outputs":[{"output_type":"stream","text":["Finished reading the final set of COVID19 Dataset (2700 samples found, each dim = 78)\n","Saving model (epoch =    1, loss = 314.2041)\n","Saving model (epoch =    2, loss = 210.9952)\n","Saving model (epoch =    3, loss = 33.2853)\n","Saving model (epoch =    4, loss = 13.1029)\n","Saving model (epoch =    5, loss = 6.5696)\n","Saving model (epoch =    6, loss = 4.2047)\n","Saving model (epoch =    7, loss = 3.1574)\n","Saving model (epoch =    8, loss = 2.5902)\n","Saving model (epoch =    9, loss = 2.2301)\n","Saving model (epoch =   10, loss = 1.9636)\n","Saving model (epoch =   11, loss = 1.7878)\n","Saving model (epoch =   12, loss = 1.5961)\n","Saving model (epoch =   13, loss = 1.3893)\n","Saving model (epoch =   14, loss = 1.3182)\n","Saving model (epoch =   15, loss = 1.2870)\n","Saving model (epoch =   16, loss = 1.2003)\n","Saving model (epoch =   17, loss = 1.1698)\n","Saving model (epoch =   18, loss = 1.1336)\n","Saving model (epoch =   20, loss = 1.1220)\n","Saving model (epoch =   22, loss = 1.1050)\n","Saving model (epoch =   23, loss = 1.0511)\n","Saving model (epoch =   27, loss = 1.0420)\n","Saving model (epoch =   28, loss = 0.9924)\n","Saving model (epoch =   33, loss = 0.9829)\n","Saving model (epoch =   37, loss = 0.9634)\n","Saving model (epoch =   38, loss = 0.9482)\n","Saving model (epoch =   40, loss = 0.9397)\n","Saving model (epoch =   42, loss = 0.9001)\n","Saving model (epoch =   46, loss = 0.8933)\n","Saving model (epoch =   47, loss = 0.8833)\n","Saving model (epoch =   50, loss = 0.8790)\n","Saving model (epoch =   51, loss = 0.8568)\n","Saving model (epoch =   52, loss = 0.8458)\n","Saving model (epoch =   54, loss = 0.8445)\n","Saving model (epoch =   56, loss = 0.8408)\n","Saving model (epoch =   59, loss = 0.8398)\n","Saving model (epoch =   62, loss = 0.8395)\n","Saving model (epoch =   64, loss = 0.8385)\n","Saving model (epoch =   66, loss = 0.8384)\n","Saving model (epoch =   67, loss = 0.8370)\n","Saving model (epoch =   71, loss = 0.8353)\n","Saving model (epoch =   77, loss = 0.8353)\n","Saving model (epoch =   78, loss = 0.8352)\n","Saving model (epoch =   79, loss = 0.8349)\n","Saving model (epoch =   80, loss = 0.8349)\n","Saving model (epoch =   81, loss = 0.8335)\n","Saving model (epoch =   82, loss = 0.8334)\n","Saving model (epoch =   83, loss = 0.8329)\n","Saving model (epoch =   90, loss = 0.8325)\n","Saving model (epoch =   91, loss = 0.8306)\n","Saving model (epoch =   95, loss = 0.8299)\n","Saving model (epoch =   96, loss = 0.8290)\n","Saving model (epoch =   99, loss = 0.8283)\n","Saving model (epoch =  100, loss = 0.8280)\n","Saving model (epoch =  101, loss = 0.8260)\n","Saving model (epoch =  102, loss = 0.8253)\n","Saving model (epoch =  104, loss = 0.8249)\n","Saving model (epoch =  105, loss = 0.8249)\n","Saving model (epoch =  108, loss = 0.8247)\n","Saving model (epoch =  113, loss = 0.8246)\n","Saving model (epoch =  116, loss = 0.8246)\n","Saving model (epoch =  119, loss = 0.8245)\n","Saving model (epoch =  121, loss = 0.8244)\n","Saving model (epoch =  123, loss = 0.8244)\n","Saving model (epoch =  125, loss = 0.8243)\n","Saving model (epoch =  129, loss = 0.8242)\n","Saving model (epoch =  131, loss = 0.8242)\n","Saving model (epoch =  134, loss = 0.8241)\n","Saving model (epoch =  136, loss = 0.8241)\n","Saving model (epoch =  140, loss = 0.8239)\n","Saving model (epoch =  143, loss = 0.8238)\n","Saving model (epoch =  148, loss = 0.8237)\n","Saving model (epoch =  150, loss = 0.8236)\n","Saving model (epoch =  151, loss = 0.8235)\n","Saving model (epoch =  152, loss = 0.8234)\n","Saving model (epoch =  155, loss = 0.8234)\n","Saving model (epoch =  158, loss = 0.8234)\n","Saving model (epoch =  159, loss = 0.8234)\n","Saving model (epoch =  166, loss = 0.8234)\n","Saving model (epoch =  167, loss = 0.8234)\n","Saving model (epoch =  169, loss = 0.8234)\n","Saving model (epoch =  170, loss = 0.8234)\n","Saving model (epoch =  171, loss = 0.8234)\n","Saving model (epoch =  177, loss = 0.8234)\n","Saving model (epoch =  179, loss = 0.8234)\n","Saving model (epoch =  180, loss = 0.8234)\n","Saving model (epoch =  182, loss = 0.8234)\n","Saving model (epoch =  183, loss = 0.8234)\n","Saving model (epoch =  185, loss = 0.8233)\n","Saving model (epoch =  191, loss = 0.8233)\n","Saving model (epoch =  196, loss = 0.8233)\n","Saving model (epoch =  201, loss = 0.8233)\n","Saving model (epoch =  202, loss = 0.8233)\n","Saving model (epoch =  203, loss = 0.8233)\n","Saving model (epoch =  209, loss = 0.8233)\n","Saving model (epoch =  211, loss = 0.8233)\n","Saving model (epoch =  212, loss = 0.8233)\n","Saving model (epoch =  214, loss = 0.8233)\n","Saving model (epoch =  218, loss = 0.8233)\n","Saving model (epoch =  219, loss = 0.8233)\n","Saving model (epoch =  223, loss = 0.8233)\n","Saving model (epoch =  226, loss = 0.8233)\n","Saving model (epoch =  230, loss = 0.8233)\n","Saving model (epoch =  231, loss = 0.8233)\n","Saving model (epoch =  235, loss = 0.8233)\n","Saving model (epoch =  240, loss = 0.8233)\n","Saving model (epoch =  243, loss = 0.8233)\n","Saving model (epoch =  246, loss = 0.8233)\n","Saving model (epoch =  249, loss = 0.8233)\n","Saving model (epoch =  251, loss = 0.8233)\n","Saving model (epoch =  252, loss = 0.8233)\n","Saving model (epoch =  253, loss = 0.8233)\n","Saving model (epoch =  257, loss = 0.8233)\n","Saving model (epoch =  260, loss = 0.8233)\n","Saving model (epoch =  265, loss = 0.8233)\n","Saving model (epoch =  278, loss = 0.8233)\n","Saving model (epoch =  284, loss = 0.8233)\n","Saving model (epoch =  287, loss = 0.8233)\n","Saving model (epoch =  294, loss = 0.8233)\n","Saving model (epoch =  297, loss = 0.8233)\n","Saving model (epoch =  298, loss = 0.8233)\n","Saving model (epoch =  301, loss = 0.8233)\n","Saving model (epoch =  316, loss = 0.8233)\n","Finished training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qo55fOrm7QhV","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1615861281163,"user_tz":-480,"elapsed":672,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"21a2bf5d-5ee1-4e4d-d466-8dfc1527ce37"},"source":["plot_learning_curve_final(model_loss_record, title='final deep model')"],"execution_count":116,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"4duy-Dy0869L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615860084031,"user_tz":-480,"elapsed":401,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"7c7fe595-eff2-4971-d73d-614bb5381825"},"source":["# del model\n","model = NeuralNet(tt_set.dataset.dim).to(device)\n","ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n","model.load_state_dict(ckpt)"],"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"markdown","metadata":{"id":"aQikz3IPiyPf"},"source":["# **Testing**\n","The predictions of your model on testing set will be stored at `pred.csv`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8cTuQjQQOon","executionInfo":{"status":"ok","timestamp":1615860086591,"user_tz":-480,"elapsed":748,"user":{"displayName":"谢仑辰","photoUrl":"","userId":"11396720971206250404"}},"outputId":"ef3ee248-e822-4baa-8818-8ae82c5ccf04"},"source":["def save_pred(preds, file):\n","    ''' Save predictions to specified file '''\n","    print('Saving results to {}'.format(file))\n","    with open(file, 'w') as fp:\n","        writer = csv.writer(fp)\n","        writer.writerow(['id', 'tested_positive'])\n","        for i, p in enumerate(preds):\n","            writer.writerow([i, p])\n","\n","preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n","save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"],"execution_count":103,"outputs":[{"output_type":"stream","text":["Saving results to pred.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nfrVxqJanGpE"},"source":["# **Hints**\n","\n","## **Simple Baseline**\n","* Run sample code\n","\n","## **Medium Baseline**\n","* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n","\n","## **Strong Baseline**\n","* Feature selection (what other features are useful?)\n","* DNN architecture (layers? dimension? activation function?)\n","* Training (mini-batch? optimizer? learning rate?)\n","* L2 regularization\n","* There are some mistakes in the sample code, can you find them?"]},{"cell_type":"markdown","metadata":{"id":"9tmCwXgpot3t"},"source":["# **Reference**\n","This code is completely written by Heng-Jui Chang @ NTUEE.  \n","Copying or reusing this code is required to specify the original author. \n","\n","E.g.  \n","Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"]}]}