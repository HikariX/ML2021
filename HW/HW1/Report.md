# Report

在第一次作业中，我们主要尝试了神经网络的搭建和简单训练。这一过程基本由助教完成，我的主要工作存在于网络调参和一些细节方法使用。

首先，对于原始的网络结构，我将参数取出或添加weight_decay超参数以达到正则化的效果。经过实验证明，其确实有一定改善，但是正则化参数不可过大，否则模型将过于简单。

在选取激活函数的时候，ReLU的表现已经足够好，所以我不再改进这一部分。

在助教提示下我使用40个州的特征和2个诊断是否为阳性的特征进行训练，确实观察到模型可以超过medium baseline。在此基础上我阅读特征内容，发现里头包含：类新冠疾病、行为类型、心理问题类型三类特征。首先我们知道新冠和情绪波动没有太大影响，所以我首先剔除了心理问题这一块特征，后在其他特征上测试发现行为类型剔除也没有太大影响。这说明只要知道人群是否有类新冠疾病，再判定其的新冠可能性就足够了。

在复用助教代码的过程中我注意到，该代码对于train、val、test set均使用了normalization，但是均针对不同的数据集使用各自的数据进行normalize，这很显然存在问题。经过改进，我的代码均为对train set进行计算后将数据取出，对val set和test set进行normalize。

在开始的几次训练中我均发现，模型在给定的val set表现十分优秀，loss已经降到0.7x，然而提交后的score却飙升到1.1x。这其实是train set、val set和test set的不匹配问题。考虑到val set已经和train set隔离开来，所以这种不匹配其实是训练时候数据划分的问题，恰好这类数据在测试集很多，所以反应的分数差距大。假设之前的val set里头有较多train set的数据，那么效果一定就会更好。由此，我使用了10-fold cross validation，将10个模型的结果作平均观察情况。果然对于某些fold，可以看到val set的loss为1.0x，比较接近test set。这些时候的val set可能才和test set的数据分布比较类似。通过这一方法，最终平均的模型loss和test set的loss已经十分接近（比如只相差0.1）。另外我也画出了平均后的训练图像作为对比。

<img src="截屏2021-03-18 16.09.54.png" alt="截屏2021-03-18 16.09.54"  />

不难看出随着训练增加，val loss（dev）是在抬升的，说明还是存在过拟合问题。当然我通过输出最小val loss的训练轮次，可以直接规定最后训练多少次为止。最后将所有数据一起加入训练，得到最终模型对test set进行预测即可。

调节网络结构的时候发现，过于复杂的结构已经没有效果，但目前训练进入瓶颈，所以到此为止，不再过多浪费时间。其中比较好的一种网络结构如下：

```python
self.net = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),

            nn.Linear(32, 128),
            nn.ReLU(),
            
            nn.Linear(128, 128),
            nn.ReLU(),

            nn.Linear(128, 32),
            nn.ReLU(),

            nn.Linear(32, 1)
        )
```

## 训练日志

3.14

L2正则化中，我尝试了直接将参数取出加入loss和在优化器中加入weight_decay两种方法，效果基本类似。并且实验中发现如果正则项权重达到0.1，效果反而会稍微劣化。

使用Sigmoid函数于事无补，反而让结果更差了。

momentum在较大（0.95）或较小（0.5）的时候效果均不佳，还是0.9比较好。

learning rate设置在0.001足矣。

实验发现如果train loss下降很多但是和val loss相差较大，这种情况在test set上效果会不好！该情况是在使用所有数据时候产生的，是否有些特征在第三天会和前两天完全不一样 所以别用第一天的特征？然而，只有第三天特征的训练loss极低，验证集loss0.7x，但是最终test set的分数达到了2.74！说明overfitting问题还是蛮严重的。



3.15

经过观看数据，我将对疾病的情绪特征剔除，使用其余特征进行训练。

检查到normalize方法对不同的数据集用不同的正则化，应该存在问题，修正为用训练数据集的均值和方差进行正则化。

动量参数设置为0.9并不一定最好，改为0.4效果不错。

在使用最多特征训练时，训练误差和验证集误差都下降且接近0.7x，最终测试分数1.07，说明这时候选用了较多特征但是并不会受到过拟合等问题困扰，说明新的正则化方法有效。但是测试分数和使用57/75号特征的结果差不多甚至更差（考虑明天把momentum重新设为0.9看看分数会不会变）



3.16

首先在全体数据上误差已经降到了0.8x，但是测试分数1.1x，效果极差。所以我又去除了一些特征，只使用covid-like illness这些特征，网络基本为3-4层，比如input-32，32-128，128-128，128-32，32-1和input-32，32-64，64-32，32-1。此时训练分数也为0.9左右，对不同验证集的平均误差还是和训练集有差距，但意外发现测试分数已经降到了0.92-0.93，这说明之前训练集-验证集有分数差异并不是过拟合（确实验证集误差也是在下降），而表现在测试结果上差是因为只用了一个验证集，没法代表所有数据。

本日实验说明多余特征确实会让网络变差，但是只用test_positive也不够，还是要加入些特征。另外，今天开始在全体数据集上进行训练后提交，效果不错，因时间问题未进行对照实验，后续有机会可以补上。



3.17

去掉第一天数据效果略微变差，观察发现，cross val的效果和最终test set最接近，所以还是应该以cross的平均训练结果为准，而不能看train_total

经过大量尝试发现，batchnorm没用，增加网络深度也没有效果，激活函数用ReLU足够。网络结构一般为4层，64-128-32-1。

额外记录了64-256-64-1和64-512-64-1两个结果，分别为pred-21和22，其中22的batchsize改成了135。个人感觉目前修改优化参数之类已经无济于事，只有真正改进网络和选取特征才能让效果变好。又加了活动的最后一个特征，即为pred-23。三个数据分数均为0.94，虽无较大改善，但效果已不错。



3.19

把所有数据放入，观察了不同fold的loss发现极低，最终平均val loss为0.89。由此我尝试训练一个全数据的网络，但最终test set loss为2.2176，劣化严重，这某种程度上说明测试数据和训练数据的分布是有所差异的...

