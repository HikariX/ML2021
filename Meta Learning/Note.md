# Meta Learning

## Meta Learning

### Introduction of Meta Learning

Meta Learning（元学习）是一种让机器学习如何学习的方法。下图为一种机器学习流程，通过训练数据集对分类器$f*$进行学习，在测试数据集上进行验证。这一过程表述为任务函数F。然而，是否有方法对F进行学习，即获得一种，遇见不同数据集，都能学到对应$f*$的算法？

<img src="image-20211227230020445.png" alt="image-20211227230020445" style="zoom:25%;" />

#### 训练三步骤

**1.学什么**

对于上述的学习任务，实际上可学习的也是网络中的各类参数，包括超参数。

<img src="image-20211227230652690.png" alt="image-20211227230652690" style="zoom:25%;" />

**2.定义损失函数**

对于传统机器学习任务，在训练集进行训练后，与测试集作损失函数计算即完成任务。而元学习则需要对所有任务所对应模型参数的损失函数结果相加（也有其他加权方法）。

<img src="image-20211227231037752.png" alt="image-20211227231037752" style="zoom:25%;" />

**3.进行优化**

最小化所定义的损失函数。当然，此时也许无法进行梯度下降（毕竟所涉及的参数众多）。所以可能需要使用强化学习或进化算法。

***注：***在元学习中，训练过程的输入是一系列的任务，对每个任务，将训练集得到参数在测试集的损失作为总体损失的一部分。此时每个任务的测试集是可以被获取的。这时候对于元学习框架本身，其“训练集”是用来训练的任务的所有部分（包括任务的不同数据集），而“测试集”是用来测试的任务。此时，测试任务里头的训练和测试数据集对于元学习任务才是不可访问的内容。

#### 机器学习与元学习的对比

**目标**

机器学习找到一个映射函数$f$，其能完成某任务；元学习找到一个学习函数$F$，其能够找到映射函数$f$。

<img src="image-20211227232758440.png" alt="image-20211227232758440" style="zoom:25%;" />

**训练数据**

机器学习针对自己的训练数据进行训练；元学习针对不同任务里头的训练与测试数据进行训练。

<img src="image-20211227232842266.png" alt="image-20211227232842266" style="zoom:25%;" />

**损失函数**

机器学习的损失函数是任务里头所有样本损失函数总和；元学习的损失函数是所有任务的（各自所有样本）损失函数总和。

<img src="image-20211227233042070.png" alt="image-20211227233042070" style="zoom:25%;" />